<!doctype html><html><head><meta charset="utf-8">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js">
<link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/texmath.css">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/vscode-texmath.css">

</head><body>
<h1 id="week-2-notes-1" data-line="0" class="code-line">Week 2 Notes</h1>
<h2 id="case-studies-1" data-line="2" class="code-line">Case studies</h2>
<ul>
<li data-line="4" class="code-line">LeNet-5</li>
<li data-line="5" class="code-line">AlexNet</li>
<li data-line="6" class="code-line">VGG</li>
</ul>
<p data-line="8" class="code-line">Laid foundations for modern CV.</p>
<ul>
<li data-line="10" class="code-line">ResNet (152)</li>
<li data-line="11" class="code-line">Inception</li>
</ul>
<h2 id="classic-networks-1" data-line="13" class="code-line">Classic Networks</h2>
<p data-line="15" class="code-line">You shuold read them in the order: AlexNet (easy), VGG, LeNet(hard)</p>
<h3 id="lenet-5-1" data-line="17" class="code-line">LeNet-5</h3>
<ul>
<li data-line="19" class="code-line">digit recognition</li>
<li data-line="20" class="code-line">in that age everyone used &quot;valid&quot; convolutions</li>
<li data-line="21" class="code-line">Essentially 4 conv -&gt; flatten -&gt; fc -&gt; fc -&gt; logits / softmax <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span></eq></li>
</ul>
<p data-line="23" class="code-line">Architecture:</p>
<p data-line="25" class="code-line"><img src="lenet5_arch.png" alt="lenet5_arch" class="loading" id="image-hash-4b6a8ecb07bd248956f08bae459ee6fcf4363d3835df63e2984f8b2c8653f512"></p>
<ul>
<li data-line="27" class="code-line">Not unusual to see networks that are 1000 times bigger</li>
<li data-line="28" class="code-line">width / height goes down, number of channels goes up</li>
</ul>
<p data-line="30" class="code-line"><code>conv pool conv pool .... fc fc fc .. output</code></p>
<h4 id="extra-comments-if-you-want-to-read-lenet-5-1" data-line="32" class="code-line">Extra comments if you want to read LeNet-5</h4>
<ul>
<li data-line="34" class="code-line">use sigmoid/tanh instead of ReLU</li>
<li data-line="35" class="code-line">typically every filter looks at every channel, but original LeNet-5 will not do this, it will look at single channels and complex stuff because the network was already &quot;big&quot; back then</li>
<li data-line="36" class="code-line">original LeNet-5 uses sigmoid nonlinearity after pooling.</li>
</ul>
<p data-line="38" class="code-line"><img src="lenet5_arch_extended.png" alt="lenet5_arch_extended" class="loading" id="image-hash-8056977708b559e041546de1ba0cb6c220c86222a0d070d8373d997ea787c57a"></p>
<h3 id="alexnet-1" data-line="40" class="code-line">AlexNet</h3>
<ul>
<li data-line="42" class="code-line">Original paper uses 224x224x3 but its actually 227x227</li>
<li data-line="43" class="code-line">Uses large stride, so dim shrinks quickly</li>
<li data-line="44" class="code-line">alot bigger than LeNet-5</li>
<li data-line="45" class="code-line">8 convs, flatten, 3 fc, softmax</li>
<li data-line="46" class="code-line">very similar to LeNet-5
<ul>
<li data-line="47" class="code-line">60k params (LeNet) vs 60mil params (AlexNet)</li>
</ul>
</li>
<li data-line="48" class="code-line">uses ReLU activation function</li>
</ul>
<p data-line="50" class="code-line">Architecture:</p>
<p data-line="52" class="code-line"><img src="alexnet_arch.png" alt="alexnet_arch" class="loading" id="image-hash-d893d0379be4fa7aedc74d51867ec3ed164f623f262f9e27296046e51dfacba9"></p>
<h4 id="extra-comments-if-you-want-to-read-alexnet-1" data-line="54" class="code-line">Extra comments if you want to read AlexNet</h4>
<ul>
<li data-line="56" class="code-line">uses complex training schedule on two GPU's</li>
<li data-line="57" class="code-line">uses Local Response Normalization
<ul>
<li data-line="58" class="code-line">not used much</li>
<li data-line="59" class="code-line">basic idea: looks at 1 position in H,W and look through all channels and normalize them. Inituition is that for each position in this 13x13 image you dont want too many neurons with very high activation</li>
<li data-line="60" class="code-line">this doesnt help that much.</li>
<li data-line="61" class="code-line">no one really uses it</li>
</ul>
</li>
</ul>
<p data-line="63" class="code-line"><img src="alexnet_arch_extended.png" alt="alexnet_arch_extended" class="loading" id="image-hash-12fda93351acec05f81d69d93ddf40e936bc4c4dcdee1d0eadf11e53d0ad89a5"></p>
<ul>
<li data-line="65" class="code-line">AlexNet was the gamechanger -&gt; 2012.</li>
<li data-line="66" class="code-line">One of the easier ones to read</li>
</ul>
<h3 id="vgg-16-1" data-line="68" class="code-line">VGG-16</h3>
<ul>
<li data-line="70" class="code-line">instead of having massive amounts of parameters, use smaller network</li>
<li data-line="71" class="code-line"><strong>always</strong> use conv 3x3 filters, stride=1 , same padding</li>
<li data-line="72" class="code-line">maxpool <strong>always</strong> 2x2, s=2</li>
<li data-line="73" class="code-line">much deeper network</li>
<li data-line="74" class="code-line">Essentially, because SAME convolutions and max pooling, the network shrinks very easily readable</li>
<li data-line="75" class="code-line">output = softmax (1000)</li>
<li data-line="76" class="code-line">16 in name VGG-16 refers to 16 layers that have weights</li>
<li data-line="77" class="code-line">138mil params...</li>
<li data-line="78" class="code-line">number of filters are always doubled 64-128-256-512</li>
<li data-line="79" class="code-line">relative uniform network</li>
<li data-line="80" class="code-line">in literature, VGG-19 is a bigger version of VGG-16.</li>
<li data-line="81" class="code-line">vgg-16 almost does as well</li>
</ul>
<p data-line="83" class="code-line"><code>pattern: if you go deeper, H and W go down, but channels increase</code></p>
<p data-line="85" class="code-line">Architecture:</p>
<p data-line="87" class="code-line"><img src="vgg16_arch.png" alt="vgg16_arch" class="loading" id="image-hash-e2520be0193bedb5d2532bcd7e535567910b5d0211bf3583ebde76a23f3ca5fa"></p>
<h2 id="resnets-residual-networks-1" data-line="89" class="code-line">ResNets: Residual Networks</h2>
<ul>
<li data-line="91" class="code-line">allows skip connections</li>
<li data-line="92" class="code-line">very deep &gt; 100 layers</li>
</ul>
<h3 id="residual-blocks-1" data-line="94" class="code-line">Residual blocks</h3>
<ul>
<li data-line="96" class="code-line"><eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover><mover><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><munder><munder><mrow><mo>→</mo><mtext>linear</mtext><mo>→</mo><mtext>ReLU</mtext><mo>→</mo><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>→</mo><mtext>linear</mtext><mo>→</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>&quot;shortcut / skip connection&quot;</mtext></munder><mtext>ReLU</mtext><mo>→</mo><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup></mrow><mo stretchy="true">⏞</mo></mover><mtext>main path</mtext></mover></mrow><annotation encoding="application/x-tex">\overbrace{\ssb{a}{l} \underbrace{\rightarrow \textnormal{linear} \rightarrow \textnormal{ReLU} \rightarrow \ssb{a}{l+1} \rightarrow \textnormal{linear} \rightarrow}_{\textnormal{&quot;shortcut / skip connection&quot;}} \textnormal{ReLU} \rightarrow \ssb{a}{l+2}}^{\textnormal{main path}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.9562159999999995em;vertical-align:-1.548em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4082159999999995em;"><span style="top:-3.586em;"><span class="pstrut" style="height:3.586em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5859999999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9379999999999997em;"><span style="top:-1.627em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord textrm mtight">&quot;shortcut / skip connection&quot;</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span class="svg-align" style="top:-2.352em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord textrm">linear</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord textrm">ReLU</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord textrm">linear</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.648em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.548em;"><span></span></span></span></span></span><span class="mord text"><span class="mord textrm">ReLU</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span><span class="svg-align" style="top:-4.038em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M6 548l-6-6v-35l6-11c56-104 135.3-181.3 238-232 57.3-28.7 117
-45 179-50h399577v120H403c-43.3 7-81 15-113 26-100.7 33-179.7 91-237 174-2.7
 5-6 9-10 13-.7 1-7.3 1-20 1H6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M200428 334
c-100.7-8.3-195.3-44-280-108-55.3-42-101.7-93-139-153l-9-14c-2.7 4-5.7 8.7-9 14
-53.3 86.7-123.7 153-211 199-66.7 36-137.3 56.3-212 62H0V214h199568c178.3-11.7
 311.7-78.3 403-201 6-8 9.7-12 11-12 .7-.7 6.7-1 18-1s17.3.3 18 1c1.3 0 5 4 11
 12 44.7 59.3 101.3 106.3 170 141s145.3 54.3 229 60h199572v120z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M400000 542l
-6 6h-17c-12.7 0-19.3-.3-20-1-4-4-7.3-8.3-10-13-35.3-51.3-80.8-93.8-136.5-127.5
s-117.2-55.8-184.5-66.5c-.7 0-2-.3-4-1-18.7-2.7-76-4.3-172-5H0V214h399571l6 1
c124.7 8 235 61.7 331 161 31.3 33.3 59.7 72.7 85 118l7 13v35z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.548em;"><span></span></span></span></span></span></span><span style="top:-5.508108em;"><span class="pstrut" style="height:3.586em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord textrm mtight">main path</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.548em;"><span></span></span></span></span></span></span></span></span></eq></li>
</ul>
<section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><msup><mi>W</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>b</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\ssb{z}{l+1} = \ssb{W}{l+1}\ssb{a}{l} + \ssb{b}{l+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0213299999999998em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></span></eqn></section><section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\ssb{a}{l+1} = g(\ssb{z}{l+1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></eqn></section><section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><msup><mi>W</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>b</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\ssb{z}{l+2} = \ssb{W}{l+2}\ssb{a}{l+1} + \ssb{b}{l+2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0213299999999998em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></span></eqn></section><section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\ssb{a}{l+2} = g(\ssb{z}{l+2})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></eqn></section><ul>
<li data-line="103" class="code-line">now, lets take <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\ssb{a}{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></eq> and make a &quot;shortcut / skip connection&quot;. This makes that the output is</li>
</ul>
<section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\ssb{a}{l+2} = g(\ssb{z}{l+2} + \ssb{a}{l})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></eqn></section><p data-line="107" class="code-line"><img src="resnet_residual_blocks.png" alt="resnet_residual_blocks" class="loading" id="image-hash-1a19d537198fa652e9fe228b7bc01081ffc6570d106dc202b7a0538b67427785"></p>
<ul>
<li data-line="109" class="code-line">Using Residual Blocks allows to build alot DEEPER networks</li>
</ul>
<h3 id="residual-22plain-network22-1" data-line="111" class="code-line">Residual &quot;Plain Network&quot;</h3>
<ul>
<li data-line="113" class="code-line">add all the skip connections to turn each of the blocks into residual blocks</li>
<li data-line="114" class="code-line">it turns out that if you use GD / ... As you increase the number of layers, the training error decreases but after a while it will go back up.</li>
<li data-line="115" class="code-line">in theory, having a deeper network should only help, but in reality the error goes back up</li>
<li data-line="116" class="code-line">helps with vanishing / explodin gradients</li>
</ul>
<p data-line="118" class="code-line"><img src="resnet_plain_network.png" alt="resnet_plain_network" class="loading" id="image-hash-1249d763db49696af77cc7aa6666333dbfac113e62adea2857664c5e7b0417b3"></p>
<h3 id="why-resnets-work-1" data-line="120" class="code-line">Why ResNets work</h3>
<ul>
<li data-line="122" class="code-line">making bigger networks hurts the performance of the network</li>
<li data-line="123" class="code-line">this is not true if you use residual blocks</li>
</ul>
<p data-line="125" class="code-line">Lets start the idea with a big NN. A Different net will take the same network, but adds some extra layers in the form of a residual block</p>
<p data-line="127" class="code-line"><img src="resnet_whytheywork.png" alt="resnet_whytheywork" class="loading" id="image-hash-3454e33f280c46b1e4618bdcbb6b15c48c37a62c78b03f2d73fe294f45400dc7"></p>
<ul>
<li data-line="129" class="code-line">Lets assume we use ReLU, so all activations are always greater than 0</li>
</ul>
<section><eqn><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>w</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>b</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\ssb{a}{l+2} = g(\ssb{z}{l+2} + \ssb{a}{l}) = g(\ssb{w}{l+2}\ssb{a}{l+1} + \ssb{b}{l+2} + \ssb{a}{l})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0213299999999998em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></eqn></section><ul>
<li data-line="133" class="code-line">if you apply weight decay or L2 regularization, that will tend to shrink the value of <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>W</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\ssb{W}{l+2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></eq> (and b, but not as important). If this happens, the output becomes just equal to <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\ssb{a}{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></eq>.</li>
<li data-line="134" class="code-line">the identity function is <strong>easy</strong> for residual blocks to learn because of the skip connection</li>
<li data-line="135" class="code-line">its difficult for normal networks to learn Identity, thats why larger networks hurt performance</li>
<li data-line="136" class="code-line">many times with residual blocks it will just help in performance</li>
</ul>
<p data-line="138" class="code-line">Some extra notes:</p>
<ul>
<li data-line="140" class="code-line">Typically the SAME convolution is used, so the dimensions are also taken care of with the skip connection.</li>
<li data-line="141" class="code-line">if there is a difference in shape, we can add a new matrix to multiply so that the output becomes <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>s</mi></msub><msup><mi>a</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">W_s\ssb{a}{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0379999999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span></span></span></span></span></eq> which is fo the same dimension.</li>
<li data-line="142" class="code-line">This matrix <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">W_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></eq> makes that the dimensions don't mismatch.
<ul>
<li data-line="143" class="code-line">Can be a matrix with params to be learned</li>
<li data-line="144" class="code-line">Can be a fixed matrix with zero padding: a_l with zero pads on the sides to make the dimensions work</li>
</ul>
</li>
</ul>
<p data-line="146" class="code-line"><img src="resnet_whytheywork_extra.png" alt="resnet_whytheywork_extra" class="loading" id="image-hash-52a12e3454bb28ab985b00241b21e156e7f615df60ee53200a68a3adc077ae70"></p>
<h3 id="resnet-on-images-1" data-line="148" class="code-line">ResNet on images</h3>
<ul>
<li data-line="150" class="code-line">start from plain network</li>
<li data-line="151" class="code-line">add skip connections</li>
<li data-line="152" class="code-line">there's alot of 3x3 <strong>same</strong> convolutions, thats why we add equal dimension vectors (dimension is preserved)</li>
<li data-line="153" class="code-line">When there's a pooling layer, you need to make an adjustment to the dimension</li>
<li data-line="154" class="code-line">The last layer is a fully connected layer that makes a prediction using softmax</li>
</ul>
<p data-line="156" class="code-line"><img src="resnet_whytheywork_example.png" alt="resnet_whytheywork_example" class="loading" id="image-hash-50fd08584468093cc9683f1f7db70b60a3b2b21ecbf4e5d24f63f1f0d9cb4d17"></p>
<h2 id="networks-in-networks-and-1x1-convolutions-1" data-line="158" class="code-line">Networks in Networks and 1x1 Convolutions</h2>
<ul>
<li data-line="160" class="code-line">1x1 conv = multiplication is matmul with scalar</li>
<li data-line="161" class="code-line">However, in a high dimensional volume  (c&gt;1), it makes more sense
<ul>
<li data-line="162" class="code-line">look at each of the 32 different positions</li>
<li data-line="163" class="code-line">takes elementwise product of 32numbers on the left and 32numbers of the filter.</li>
<li data-line="164" class="code-line">after, it applies a relu</li>
</ul>
</li>
<li data-line="165" class="code-line">think of it as one neuron that takes as input 32 numbers, multiplying them by 32 weights, applying nonlinearity and outputting</li>
<li data-line="166" class="code-line">if yuo have multiple convlutions, you have multiple units that take as input the slice and then building them up into a new output block</li>
</ul>
<p data-line="168" class="code-line"><img src="networks_in_networks_and_1x1conv.png" alt="networks_in_networks_and_1x1conv" class="loading" id="image-hash-2907dc0b8d9f737a624c5da35c11900ab8c1e8ad6725e6a94b208dde125c0a6c"></p>
<ul>
<li data-line="170" class="code-line">its basically having a fully connected network that applies to each of the elements, so it takes as input 32 numbers and outputs a number of filters <eq><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>n</mi><mi>c</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\ssb{n}{l+1}_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.161392em;vertical-align:-0.11659199999999997em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.5834080000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11659199999999997em;"><span></span></span></span></span></span></span></span></span></span></eq>.</li>
<li data-line="171" class="code-line">can do difficult multiplication</li>
</ul>
<p data-line="173" class="code-line"><img src="networks_in_networks_and_1x1conv_extra.png" alt="networks_in_networks_and_1x1conv_extra" class="loading" id="image-hash-51cb65ba91a635256deb0e4b633bca1a5f16ed6cf5f308a2039b7c7cb7475858"></p>
<ul>
<li data-line="175" class="code-line">also named &quot;Network in Network&quot; , by lin et al.</li>
<li data-line="176" class="code-line">An example of where a 1by1 conv is useful
<ul>
<li data-line="177" class="code-line">if the number of channels is too big and you want to shrink it (ie go from 128 -&gt; 32 channels)</li>
<li data-line="178" class="code-line">you can also keep the number of channels constant/decrease/increase</li>
<li data-line="179" class="code-line"><code>can just use this as an extra nonlinearity</code></li>
</ul>
</li>
</ul>
<p data-line="181" class="code-line"><img src="networks_in_networks_and_1x1conv_example.png" alt="networks_in_networks_and_1x1conv_example" class="loading" id="image-hash-db5b224c24bee982e56c60e2039eca7c421087da08c8f3d39b5b46d5a6abb3c3"></p>
<h2 id="inception-network-1" data-line="183" class="code-line">Inception Network</h2>
<ul>
<li data-line="185" class="code-line">arch is more complex, but works really well</li>
<li data-line="186" class="code-line">instead of choosing what size of convolution you want, do them all</li>
<li data-line="187" class="code-line">stack up multiple blocks of convolutions, making the dimensions match up</li>
<li data-line="188" class="code-line">also include pooling. In order to make the dimensions match, you need to add padding.</li>
</ul>
<p data-line="190" class="code-line"><img src="inceptionnet_motivation.png" alt="inceptionnet_motivation" class="loading" id="image-hash-6fcbd423579c80ec034b1a50bfe2334beb33adb4f4094bbd3c6bc9859d83a3e2"></p>
<p data-line="192" class="code-line">Above is called an inception volume</p>
<ul>
<li data-line="194" class="code-line">actually increases the number of channels</li>
<li data-line="195" class="code-line">You dont need to pick any filter size / ...</li>
<li data-line="196" class="code-line">Let the network learn what it needs</li>
</ul>
<p data-line="198" class="code-line">However, the computational cost is very big. Lets focus on the 5x5 convolution of the above image below.</p>
<ul>
<li data-line="200" class="code-line">you have 32 filters</li>
<li data-line="201" class="code-line">each filter is 5x5x192</li>
<li data-line="202" class="code-line">output is 28x28x32</li>
<li data-line="203" class="code-line">this means that we need to calculate 28x28x32 x 5x5x192 = 120million computations for only this block</li>
</ul>
<p data-line="205" class="code-line"><img src="inceptionnet_motivation_5x5conv.png" alt="inceptionnet_motivation_5x5conv" class="loading" id="image-hash-57e793a166edbb298d967caa7b17e6a0a397d45e8294e66815b013073b383823"></p>
<p data-line="207" class="code-line">Alternatively, we can use a 1x1 convolution to a 16 channel volume and consequently run the 5x5 convolution to get the final output.</p>
<ul>
<li data-line="209" class="code-line">the input / output size is the same</li>
<li data-line="210" class="code-line">essentially shrink to <code>an intermediate volume called a bottleneck layer</code></li>
<li data-line="211" class="code-line">the computational cost is now
<ul>
<li data-line="212" class="code-line">First 1x1 conv: 28x28x16 (outputs) * 1x1x192 (multiplications) = 2.4mil</li>
<li data-line="213" class="code-line">second 5x5 conv: 28x28x32 (outputs) * 5x5x16 = 10.0mil</li>
<li data-line="214" class="code-line">total amount of multiplications = 12.4mil</li>
<li data-line="215" class="code-line">the number of additions is about the same as the amount of multiplications</li>
<li data-line="216" class="code-line">reduction of ~90%!</li>
</ul>
</li>
<li data-line="217" class="code-line">as long as you implement this bottleneck layer within reason, you can shrink this layer quite significantly without significantly reducing the performance.</li>
</ul>
<p data-line="219" class="code-line"><img src="inceptionnet_motivation_bottleneck.png" alt="inceptionnet_motivation_bottleneck" class="loading" id="image-hash-bb480dd7a4e73093f8525b4ef9ae84be5685f03cb863713f6dca72b0c8caab45"></p>
<h2 id="building-an-inception-network-1" data-line="221" class="code-line">Building an Inception Network</h2>
<ul>
<li data-line="223" class="code-line">Combine all the blocks</li>
<li data-line="224" class="code-line">in the pooling layer, remember to use SAME padding for pooling, so that the output height/width can be concatenated with the other outputs. Even after this it will have the same amount of channels! Add one more 1x1 conv layer to shrink the number of channels.</li>
</ul>
<p data-line="226" class="code-line"><img src="inceptionnet_arch.png" alt="inceptionnet_arch" class="loading" id="image-hash-9e3c163b0f629e7be4042622900b9699f6bf44290aa402a33921952812fc1627"></p>
<p data-line="228" class="code-line">This is one inception module. InceptionNet uses many of these modules</p>
<ul>
<li data-line="230" class="code-line">There are some extra max pooling layers to change the height and width of the network.</li>
</ul>
<p data-line="232" class="code-line"><img src="inceptionnet_arch_network.png" alt="inceptionnet_arch_network" class="loading" id="image-hash-ec208201ec94d50cfcd1f42f5611ac55e6d449cf3d2770e460df61c386878c38"></p>
<p data-line="234" class="code-line">One more detail: there are side branches (green). They take a hidden layer and use that to make a prediction (softmax).</p>
<ul>
<li data-line="236" class="code-line">helps to ensure that the computed features in intermediate layers are not too bad</li>
<li data-line="237" class="code-line">helps preventing overfitting</li>
<li data-line="238" class="code-line">also goes by the name GoogLeNet :)</li>
</ul>
<p data-line="240" class="code-line"><img src="inceptionnet_arch_network_side_branch.png" alt="inceptionnet_arch_network_side_branch" class="loading" id="image-hash-0caa6086aae5a519537a4ade67b0d69156523ca458a783e54abef78edc3e8c27"></p>
<ul>
<li data-line="242" class="code-line">inceptionNet actually refers this meme below, as motivation for the need to build deeper NN</li>
</ul>
<p data-line="244" class="code-line"><img src="inceptionnet_meme.png" alt="inceptionnet_meme" class="loading" id="image-hash-4872266c2cfaf8d45a37792b48f3b5ca0e83efc8ae09b0e9d6a5f0538bed9b0d"></p>
<h2 id="practical-advice-for-using-convnets-1" data-line="246" class="code-line">Practical advice for using ConvNets</h2>
<h3 id="using-open-source-implementations-1" data-line="248" class="code-line">Using open source implementations</h3>
<ul>
<li data-line="250" class="code-line">many networks are difficult to replicate</li>
<li data-line="251" class="code-line">look online for an open source implementation: use authors implementation!</li>
<li data-line="252" class="code-line">re-implementation could be a good exercise</li>
</ul>
<ol>
<li data-line="254" class="code-line">pick an architecture that you like</li>
<li data-line="255" class="code-line">look for open source implementation</li>
<li data-line="256" class="code-line">build from there</li>
</ol>
<ul>
<li data-line="258" class="code-line">sometimes these network take a very long time to train, we can use transfer learning to use stuff from others</li>
<li data-line="259" class="code-line">often, starting with open source implementations is a faster way to start on a new project.</li>
</ul>
<h3 id="transfer-learning-1" data-line="261" class="code-line">Transfer learning</h3>
<ul>
<li data-line="263" class="code-line">sometimes training takes many gpu's and going through the hyperparameter search process also takes long</li>
</ul>
<p data-line="265" class="code-line">Example: build pet detector and you want to detect your own cat.</p>
<ul>
<li data-line="267" class="code-line">classification problem with 3 classes.
<ul>
<li data-line="268" class="code-line">Tigga</li>
<li data-line="269" class="code-line">Misty</li>
<li data-line="270" class="code-line">neither</li>
</ul>
</li>
</ul>
<h4 id="if-your-training-set-is-small-1" data-line="272" class="code-line">If your training set is small</h4>
<ol>
<li data-line="274" class="code-line">go online and download an OS implementation + weights trained on for example ImageNet</li>
<li data-line="275" class="code-line">get rid of the softmax layer (1000 outputs) and create your own softmax unit that outputs either one of the three options (tigga, misty, neither)</li>
<li data-line="276" class="code-line">freeze all the other layers.</li>
<li data-line="277" class="code-line">by using other peoples weights you dont need alot of training sample. Use parameters such as <code>trainableParameter=0 or freeze=1</code></li>
</ol>
<ul>
<li data-line="279" class="code-line">One other trick is that you could precompute the activations of one layer and saving them to disk. This way you can train a shallow softmax model to predict. Now there is no need to precompute the activations whenever you take an epoch / pass through your training set.</li>
</ul>
<p data-line="281" class="code-line"><img src="practical_advice_transferlearning.png" alt="practical_advice_transferlearning" class="loading" id="image-hash-948586f3e38d6d45c3759ea0079ed1c21e998f49cc806518d4b8a36b55780398"></p>
<h4 id="if-your-training-set-is-medium-1" data-line="283" class="code-line">If your training set is medium</h4>
<p data-line="285" class="code-line">If you have a larger labelled dataset</p>
<ul>
<li data-line="286" class="code-line">freeze fewer layers and train the later layers.</li>
<li data-line="287" class="code-line">You can also remove the last layers and add different ones.</li>
<li data-line="288" class="code-line">essentially, you can lower the amount of layers you freeze, and increase the amount of trainable layers</li>
</ul>
<p data-line="290" class="code-line"><img src="practical_advice_transferlearning_mediumdata.png" alt="practical_advice_transferlearning_mediumdata" class="loading" id="image-hash-f8b0f01b78951db9aa1c538d8dfe503f7f7e35ee18131133228d486c5e4b9a4a"></p>
<h4 id="if-your-training-set-is-large-1" data-line="292" class="code-line">If your training set is large</h4>
<ul>
<li data-line="294" class="code-line">train the whole network</li>
<li data-line="295" class="code-line">use the previous weights as initialization (this replaces random initialization)</li>
<li data-line="296" class="code-line">The more pictures you have the more layers you can train</li>
<li data-line="297" class="code-line">this is the extreme case</li>
</ul>
<p data-line="299" class="code-line"><img src="practical_advice_transferlearning_largedata.png" alt="practical_advice_transferlearning_largedata" class="loading" id="image-hash-8002a7ab456536237877cbdbb97ec204881cc3d64ff530fe0b266ca7f251b02a"></p>
<p data-line="301" class="code-line"><code>For many applications you are better off downloading other people's weights. You should actually always do transfer learning unless you have an exceptionally large dataset and a very large computational budget</code></p>
<h3 id="data-augmentation-1" data-line="303" class="code-line">Data Augmentation</h3>
<ul>
<li data-line="305" class="code-line">for the majority of the cv problems, we just want as much data as possible</li>
<li data-line="306" class="code-line">that means that data augmentation will often help</li>
</ul>
<h4 id="common-augmentation-methods-1" data-line="308" class="code-line">Common augmentation methods</h4>
<p data-line="310" class="code-line">Mostly used</p>
<ul>
<li data-line="312" class="code-line">mirroring</li>
<li data-line="313" class="code-line">random cropping (not perfect, but in practice it works well so long as your random crops are reasonably large subset of your original image)</li>
</ul>
<p data-line="315" class="code-line">Less used</p>
<ul>
<li data-line="317" class="code-line">rotation</li>
<li data-line="318" class="code-line">shearing</li>
<li data-line="319" class="code-line">local warping..</li>
</ul>
<p data-line="321" class="code-line"><img src="data_augmentation_common_methods.png" alt="data_augmentation_common_methods" class="loading" id="image-hash-d0e2f15c9f6a3975b447c043418a3ca5153a5059f4617ea77571177864c3efea"></p>
<ul>
<li data-line="323" class="code-line">color shifting: make additions / reductions on image channels.
<ul>
<li data-line="324" class="code-line">makes new image that is less red/ more green /. ...</li>
<li data-line="325" class="code-line">in practice, the changing values are drawn from a distribution</li>
<li data-line="326" class="code-line">changes in color might be possible in the real world, so this makes your algo more robust vs that</li>
<li data-line="327" class="code-line">there are different ways of sampling RGB
<ul>
<li data-line="328" class="code-line">you can do PCA color augmentation</li>
<li data-line="329" class="code-line">ie. if your image is mainly purple, ie mainly has red and blue tints and very little green, PCA color augmentation will add and subtract alot from red and blue but less from green</li>
</ul>
</li>
</ul>
</li>
</ul>
<p data-line="331" class="code-line"><img src="data_augmentation_color_shifting.png" alt="data_augmentation_color_shifting" class="loading" id="image-hash-3da2363ef5df7adb592502707821f2c8f3a3d8926bd58160c063ec89b5808d00"></p>

</body></html>